
import requests
url="https://www.scrapethissite.com/pages/simple/"
res=requests.get(url)
print(res.status_code)


if res.status_code==200:
    print(res.headers)
with open("scraped_data/data12.html","w",encoding='utf-8') as f:
    f.write(res.text)
     


#beatutifulsop
from bs4 import BeautifulSoup
with open ("scraped_data/data12.html","r")as f:
    html_content=f.read()

soup=BeautifulSoup(html_content,"lxml")



all_h3=soup.find_all('h3')
all_countries=[]
for h3 in all_h3:
    name=h3.get_text(strip=True)
   
    population=(h3.find_next('div').select('span.country-population')[0].get_text(strip=True))
    all_countries.append([name,population])
    


all_countries
import pandas as pd
table=pd.DataFrame(all_countries)
table.fillna('none')
table


table.to_csv("clean_data/country.csv",index=False)
